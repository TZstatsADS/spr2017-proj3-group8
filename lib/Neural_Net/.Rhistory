q <- c(1,4)
sample(q, 1)
sample(q, 1)
q <- c(5)
sample(q, 1)
q <- c(5)
sample(q, 1)
sample(q, 1)
sample(q, 1)
sample(q, 1)
q <- c(1,5)
q <- ifelse(length(q)==1, q, sample(q,1))
q
q
q <- c(5)
q <- ifelse(length(q)==1, q, sample(q,1))
q
q
train <- function(X,w,y){
p <- ncol(X)
theta <- m <- err<- rep(NA, p)
for (j in 1:p){
x_order <- order(X[,j])
x_j <- X[x_order,j]
y_j <- as.numeric(y[x_order])
y_j <- as.numeric(ifelse(y_j==1, -1, 1))
w_j <- w[x_order]
w_cum <- cumsum(w_j * y_j)
w_cum[duplicated(x_j)==1] <- NA
maximum <- max(abs(w_cum), na.rm = TRUE)
indices_split <- which(abs(w_cum)==maximum)
idx_split <- ifelse(length(indices_split) > 1, sample(indices_split,1), indices_split)
theta[j] <- x_j[idx_split]
m[j] <- sign(w_cum[idx_split])
c_j <- ifelse(x_j > x_j[idx_split],-m[j],m[j])
err[j] <- w_j %*% (c_j!=y_j)
}
bestClassifiers <- which(err == min(err))
bestClassifier <- ifelse(length(bestClassifiers)==1, bestClassifiers, sample(bestClassifiers,1))
#secondBestClassifier <- which(err == sort(err)[2])
#bestClassifier <- secondBestClassifier
pars <- list(j=bestClassifier, theta = theta[bestClassifier], m = m[bestClassifier])
return(pars)
}
X <- as.data.frame(uspsdata)
y <- unlist(uspscl)
K <- 5
B <- 3
n <- nrow(X)
trainErr <- validErr <- rep(NA, K)
avgTrainErr <- avgValidErr <- rep(NA, B)
bins <- rep(1:K, n / K)
X_n <- split(X, bins)
Y_n <- split(y, bins)
for (b in 1:B) {
for (i in 1:K) {
print(c(b,i))
trainY <- unlist(Y_n[c(1:K)[c(1:K)!=i]])
validY <- Y_n[[i]]
trainX <- X_n[c(1:K)[c(1:K)!=i]]
trainX <- do.call("rbind",trainX)
trainX <- as.data.frame(trainX)
validX <- X_n[[i]]
q <- adaBoost(trainX, trainY, b)
trainPreds <- agg_class(trainX, q$alpha, q$allPars)
validPreds <- agg_class(validX, q$alpha, q$allPars)
trainErr[i] <- sum(trainY != trainPreds)/nrow(trainX)
validErr[i] <- sum(validY != validPreds)/nrow(validX)
}
avgTrainErr[b] <- mean(trainErr)
avgValidErr[b] <- mean(validErr)
}
adaBoost <- function(X, y, B){
n <- nrow(X)
w <- rep(1/n, times = n)
alpha <- rep(0,times=B)
allPars <- rep(list(list()),B)
for(b in 1:B){
allPars[[b]] <- train(X, w, y)
misClass <- (y != classify(X, allPars[[b]]))
e <- (w %*% misClass/sum(w))
alpha[b] <- log((1-e)/e)
w <- w * exp(alpha[b] * misClass)
}
return(list(allPars=allPars, alpha=alpha))
}
for (b in 1:B) {
for (i in 1:K) {
print(c(b,i))
trainY <- unlist(Y_n[c(1:K)[c(1:K)!=i]])
validY <- Y_n[[i]]
trainX <- X_n[c(1:K)[c(1:K)!=i]]
trainX <- do.call("rbind",trainX)
trainX <- as.data.frame(trainX)
validX <- X_n[[i]]
q <- adaBoost(trainX, trainY, b)
trainPreds <- agg_class(trainX, q$alpha, q$allPars)
validPreds <- agg_class(validX, q$alpha, q$allPars)
trainErr[i] <- sum(trainY != trainPreds)/nrow(trainX)
validErr[i] <- sum(validY != validPreds)/nrow(validX)
}
avgTrainErr[b] <- mean(trainErr)
avgValidErr[b] <- mean(validErr)
}
adaBoost <- function(X, y, B){
n <- nrow(X)
w <- rep(1/n, times = n)
alpha <- rep(0,times=B)
allPars <- rep(list(list()),B)
for(b in 1:B){
allPars[[b]] <- train(X, w, y)
misClass <- (y != classify(X, allPars[[b]]))
e <- (w %*% misClass/sum(w))
alpha[b] <- log((1-e)/e)
w <- w * exp(alpha[b] * misClass)
}
return(list(allPars=allPars, alpha=alpha))
}
for (b in 1:B) {
for (i in 1:K) {
trainY <- unlist(Y_n[c(1:K)[c(1:K)!=i]])
validY <- Y_n[[i]]
trainX <- X_n[c(1:K)[c(1:K)!=i]]
trainX <- do.call("rbind",trainX)
trainX <- as.data.frame(trainX)
validX <- X_n[[i]]
q <- adaBoost(trainX, trainY, b)
trainPreds <- agg_class(trainX, q$alpha, q$allPars)
validPreds <- agg_class(validX, q$alpha, q$allPars)
trainErr[i] <- sum(trainY != trainPreds)/nrow(trainX)
validErr[i] <- sum(validY != validPreds)/nrow(validX)
}
avgTrainErr[b] <- mean(trainErr)
avgValidErr[b] <- mean(validErr)
}
X <- as.data.frame(uspsdata)
y <- unlist(uspscl)
K <- 5
B <- 25
n <- nrow(X)
trainErr <- validErr <- rep(NA, K)
avgTrainErr <- avgValidErr <- rep(NA, B)
bins <- rep(1:K, n / K)
X_n <- split(X, bins)
Y_n <- split(y, bins)
for (b in 1:B) {
for (i in 1:K) {
trainY <- unlist(Y_n[c(1:K)[c(1:K)!=i]])
validY <- Y_n[[i]]
trainX <- X_n[c(1:K)[c(1:K)!=i]]
trainX <- do.call("rbind",trainX)
trainX <- as.data.frame(trainX)
validX <- X_n[[i]]
q <- adaBoost(trainX, trainY, b)
trainPreds <- agg_class(trainX, q$alpha, q$allPars)
validPreds <- agg_class(validX, q$alpha, q$allPars)
trainErr[i] <- sum(trainY != trainPreds)/nrow(trainX)
validErr[i] <- sum(validY != validPreds)/nrow(validX)
}
avgTrainErr[b] <- mean(trainErr)
avgValidErr[b] <- mean(validErr)
}
avgTrainErr
avgTestnErr
avgTestErr
avgValidErr
train <- function(X,w,y){
p <- ncol(X)
theta <- m <- err<- rep(NA, p)
for (j in 1:p){
x_order <- order(X[,j])
x_j <- X[x_order,j]
y_j <- as.numeric(y[x_order])
y_j <- as.numeric(ifelse(y_j==1, -1, 1))
w_j <- w[x_order]
w_cum <- cumsum(w_j * y_j)
w_cum[duplicated(x_j)==1] <- NA
maximum <- max(abs(w_cum), na.rm = TRUE)
indices_split <- which(abs(w_cum)==maximum)
idx_split <- ifelse(length(indices_split) > 1, min(indices_split), indices_split)
theta[j] <- x_j[idx_split]
m[j] <- sign(w_cum[idx_split])
c_j <- ifelse(x_j > x_j[idx_split],-m[j],m[j])
err[j] <- w_j %*% (c_j!=y_j)
}
bestClassifiers <- which(err == min(err))
bestClassifier <- ifelse(length(bestClassifiers)==1, bestClassifiers, min(bestClassifiers))
#secondBestClassifier <- which(err == sort(err)[2])
#bestClassifier <- secondBestClassifier
pars <- list(j=bestClassifier, theta = theta[bestClassifier], m = m[bestClassifier])
return(pars)
}
X <- as.data.frame(uspsdata)
y <- unlist(uspscl)
K <- 5
B <- 100
n <- nrow(X)
trainErr <- validErr <- rep(NA, K)
avgTrainErr <- avgValidErr <- rep(NA, B)
bins <- rep(1:K, n / K)
X_n <- split(X, bins)
Y_n <- split(y, bins)
B <- 10
n <- nrow(X)
trainErr <- validErr <- rep(NA, K)
avgTrainErr <- avgValidErr <- rep(NA, B)
bins <- rep(1:K, n / K)
X_n <- split(X, bins)
Y_n <- split(y, bins)
for (b in 1:B) {
for (i in 1:K) {
trainY <- unlist(Y_n[c(1:K)[c(1:K)!=i]])
validY <- Y_n[[i]]
trainX <- X_n[c(1:K)[c(1:K)!=i]]
trainX <- do.call("rbind",trainX)
trainX <- as.data.frame(trainX)
validX <- X_n[[i]]
q <- adaBoost(trainX, trainY, b)
trainPreds <- agg_class(trainX, q$alpha, q$allPars)
validPreds <- agg_class(validX, q$alpha, q$allPars)
trainErr[i] <- sum(trainY != trainPreds)/nrow(trainX)
validErr[i] <- sum(validY != validPreds)/nrow(validX)
}
avgTrainErr[b] <- mean(trainErr)
avgValidErr[b] <- mean(validErr)
}
avgValidErr
avgTrainErr
plot(avgTrainErr)
plot(avgValidErr)
plot(avgTrainErr)
X <- as.data.frame(uspsdata)
y <- unlist(uspscl)
K <- 5
B <- 100
n <- nrow(X)
trainErr <- validErr <- rep(NA, K)
avgTrainErr <- avgValidErr <- rep(NA, B)
bins <- rep(1:K, n / K)
X_n <- split(X, bins)
Y_n <- split(y, bins)
for (b in 1:B) {
for (i in 1:K) {
trainY <- unlist(Y_n[c(1:K)[c(1:K)!=i]])
validY <- Y_n[[i]]
trainX <- X_n[c(1:K)[c(1:K)!=i]]
trainX <- do.call("rbind",trainX)
trainX <- as.data.frame(trainX)
validX <- X_n[[i]]
q <- adaBoost(trainX, trainY, b)
trainPreds <- agg_class(trainX, q$alpha, q$allPars)
validPreds <- agg_class(validX, q$alpha, q$allPars)
trainErr[i] <- sum(trainY != trainPreds)/nrow(trainX)
validErr[i] <- sum(validY != validPreds)/nrow(validX)
}
avgTrainErr[b] <- mean(trainErr)
avgValidErr[b] <- mean(validErr)
}
plot(avgTrainErr, type="l", xlab="Boosting Iteration", ylab="Training Error")
plot(avgValidErr, type="l", xlab="Boosting Iteration", ylab="Test Error")
plot(avgValidErr, type="l", xlab="Boosting Iteration", ylab="Test Error")
plot(avgTrainErr, type="l", xlab="Boosting Iteration", ylab="Training Error")
plot(avgValidErr, type="l", xlab="Boosting Iteration", ylab="Test Error")
train <- function(X,w,y){
p <- ncol(X)
theta <- m <- err<- rep(NA, p)
for (j in 1:p){
x_order <- order(X[,j])
x_j <- X[x_order,j]
y_j <- as.numeric(y[x_order])
y_j <- as.numeric(ifelse(y_j==1, -1, 1))
w_j <- w[x_order]
w_cum <- cumsum(w_j * y_j)
w_cum[duplicated(x_j)==1] <- NA
maximum <- max(abs(w_cum), na.rm = TRUE)
if (maximum == max(w_cum, na.rm = TRUE)){
max_ind <- TRUE
} else {
max_ind <- FALSE
maximum <- -maximum
}
indices_split <- which(w_cum==maximum)
idx_split <- ifelse(length(indices_split) > 1, min(indices_split), indices_split)
theta[j] <- x_j[idx_split]
m[j] <- sign(w_cum[idx_split])
c_j <- ifelse(x_j > x_j[idx_split],-m[j],m[j])
err[j] <- w_j %*% (c_j!=y_j)
}
bestClassifiers <- which(err == min(err))
bestClassifier <- ifelse(length(bestClassifiers)==1, bestClassifiers, min(bestClassifiers))
#secondBestClassifier <- which(err == sort(err)[2])
#bestClassifier <- secondBestClassifier
pars <- list(j=bestClassifier, theta = theta[bestClassifier], m = m[bestClassifier])
return(pars)
}
X <- as.data.frame(uspsdata)
y <- unlist(uspscl)
K <- 5
B <- 10
n <- nrow(X)
trainErr <- validErr <- rep(NA, K)
avgTrainErr <- avgValidErr <- rep(NA, B)
bins <- rep(1:K, n / K)
X_n <- split(X, bins)
Y_n <- split(y, bins)
for (b in 1:B) {
for (i in 1:K) {
trainY <- unlist(Y_n[c(1:K)[c(1:K)!=i]])
validY <- Y_n[[i]]
trainX <- X_n[c(1:K)[c(1:K)!=i]]
trainX <- do.call("rbind",trainX)
trainX <- as.data.frame(trainX)
validX <- X_n[[i]]
q <- adaBoost(trainX, trainY, b)
trainPreds <- agg_class(trainX, q$alpha, q$allPars)
validPreds <- agg_class(validX, q$alpha, q$allPars)
trainErr[i] <- sum(trainY != trainPreds)/nrow(trainX)
validErr[i] <- sum(validY != validPreds)/nrow(validX)
}
avgTrainErr[b] <- mean(trainErr)
avgValidErr[b] <- mean(validErr)
}
plot(avgTrainErr, type="l", xlab="Boosting Iteration", ylab="Training Error")
plot(avgValidErr, type="l", xlab="Boosting Iteration", ylab="Test Error")
plot(avgTrainErr, type="l", xlab="Boosting Iteration", ylab="Training Error")
X <- as.data.frame(uspsdata)
y <- unlist(uspscl)
K <- 5
B <- 25
n <- nrow(X)
trainErr <- validErr <- rep(NA, K)
avgTrainErr <- avgValidErr <- rep(NA, B)
bins <- rep(1:K, n / K)
X_n <- split(X, bins)
Y_n <- split(y, bins)
for (b in 1:B) {
for (i in 1:K) {
trainY <- unlist(Y_n[c(1:K)[c(1:K)!=i]])
validY <- Y_n[[i]]
trainX <- X_n[c(1:K)[c(1:K)!=i]]
trainX <- do.call("rbind",trainX)
trainX <- as.data.frame(trainX)
validX <- X_n[[i]]
q <- adaBoost(trainX, trainY, b)
trainPreds <- agg_class(trainX, q$alpha, q$allPars)
validPreds <- agg_class(validX, q$alpha, q$allPars)
trainErr[i] <- sum(trainY != trainPreds)/nrow(trainX)
validErr[i] <- sum(validY != validPreds)/nrow(validX)
}
avgTrainErr[b] <- mean(trainErr)
avgValidErr[b] <- mean(validErr)
}
plot(avgTrainErr, type="l", xlab="Boosting Iteration", ylab="Training Error")
plot(avgValidErr, type="l", xlab="Boosting Iteration", ylab="Test Error")
train <- function(X,w,y){
p <- ncol(X)
theta <- m <- err<- rep(NA, p)
for (j in 1:p){
x_order <- order(X[,j])
x_j <- X[x_order,j]
y_j <- as.numeric(y[x_order])
y_j <- as.numeric(ifelse(y_j==1, -1, 1))
w_j <- w[x_order]
w_cum <- cumsum(w_j * y_j)
w_cum[duplicated(x_j)==1] <- NA
maximum <- max(abs(w_cum), na.rm = TRUE)
if (maximum == max(w_cum, na.rm = TRUE)){
max_ind <- TRUE
} else {
max_ind <- FALSE
maximum <- -maximum
}
indices_split <- which(w_cum==maximum)
idx_split <- ifelse(length(indices_split) > 1, indices_split[1], indices_split)
theta[j] <- x_j[idx_split]
m[j] <- sign(w_cum[idx_split])
c_j <- ifelse(x_j > x_j[idx_split],-m[j],m[j])
err[j] <- w_j %*% (c_j!=y_j)
}
bestClassifiers <- which(err == min(err))
bestClassifier <- ifelse(length(bestClassifiers)==1, bestClassifiers, min(bestClassifiers))
#secondBestClassifier <- which(err == sort(err)[2])
#bestClassifier <- secondBestClassifier
pars <- list(j=bestClassifier, theta = theta[bestClassifier], m = m[bestClassifier])
return(pars)
}
train <- function(X,w,y){
p <- ncol(X)
theta <- m <- err<- rep(NA, p)
for (j in 1:p){
x_order <- order(X[,j])
x_j <- X[x_order,j]
y_j <- as.numeric(y[x_order])
y_j <- as.numeric(ifelse(y_j==1, -1, 1))
w_j <- w[x_order]
w_cum <- cumsum(w_j * y_j)
w_cum[duplicated(x_j)==1] <- NA
maximum <- max(abs(w_cum), na.rm = TRUE)
if (maximum == max(w_cum, na.rm = TRUE)){
max_ind <- TRUE
} else {
max_ind <- FALSE
maximum <- -maximum
}
indices_split <- which(w_cum==maximum)
idx_split <- ifelse(length(indices_split) > 1, indices_split[1], indices_split)
theta[j] <- x_j[idx_split]
m[j] <- sign(w_cum[idx_split])
c_j <- ifelse(x_j > x_j[idx_split],-m[j],m[j])
err[j] <- w_j %*% (c_j!=y_j)
}
bestClassifiers <- which(err == min(err))
bestClassifier <- ifelse(length(bestClassifiers)==1, bestClassifiers, bestClassifiers[1])
#secondBestClassifier <- which(err == sort(err)[2])
#bestClassifier <- secondBestClassifier
pars <- list(j=bestClassifier, theta = theta[bestClassifier], m = m[bestClassifier])
return(pars)
}
adaBoost <- function(X, y, B){
n <- nrow(X)
w <- rep(1/n, times = n)
alpha <- rep(0,times=B)
allPars <- rep(list(list()),B)
for(b in 1:B){
allPars[[b]] <- train(X, w, y)
misclass <- (y != classify(X, allPars[[b]]))
e <- (w %*% misclass/sum(w))
alpha[b] <- log((1-e)/e)
w <- w * exp(alpha[b] * misclass)
}
return(list(allPars=allPars, alpha=alpha))
}
X <- as.data.frame(uspsdata)
y <- unlist(uspscl)
K <- 5
B <- 20
n <- nrow(X)
trainErr <- validErr <- rep(NA, K)
avgTrainErr <- avgValidErr <- rep(NA, B)
bins <- rep(1:K, n / K)
X_n <- split(X, bins)
Y_n <- split(y, bins)
for (b in 1:B) {
for (i in 1:K) {
trainY <- unlist(Y_n[c(1:K)[c(1:K)!=i]])
validY <- Y_n[[i]]
trainX <- X_n[c(1:K)[c(1:K)!=i]]
trainX <- do.call("rbind",trainX)
trainX <- as.data.frame(trainX)
validX <- X_n[[i]]
q <- adaBoost(trainX, trainY, b)
trainPreds <- agg_class(trainX, q$alpha, q$allPars)
validPreds <- agg_class(validX, q$alpha, q$allPars)
trainErr[i] <- sum(trainY != trainPreds)/nrow(trainX)
validErr[i] <- sum(validY != validPreds)/nrow(validX)
}
avgTrainErr[b] <- mean(trainErr)
avgValidErr[b] <- mean(validErr)
}
plot(avgTrainErr, type="l", xlab="Boosting Iteration", ylab="Training Error")
plot(avgValidErr, type="l", xlab="Boosting Iteration", ylab="Test Error")
source("NN_train_test_cv.R")
source("NN_train_test_cv.R")
source("../NN_train_test_cv.R")
setwd("~/Documents/Columbia Spring 2017/Applied Data Science/spr2017-proj3-group8/lib/Neural_Net")
source("NN_train_test_cv.R")
library(data.table)
library(dplyr)
feature <- read.csv("../../output/hog_feature+sift_resize.csv", header = TRUE)
feature <- read.csv("../../output/hog_feature+sift_resize.csv", header = TRUE)
feature <- read.csv("../output/hog_feature+sift_resize.csv", header = TRUE)
feature <- read.csv("../../output/hog_feature+sift_resize.csv", header = TRUE)
feature <- read.csv("../../output/hog_feature+sift_resize.csv", header = TRUE)
feature <- read.csv("../../output/hog_feature+sift_resize.csv", header = TRUE)
getwd()
paste(getwd())
feature <- read.csv("../output/hog_feature+sift_resize.csv", header = TRUE)
source("NN_train_test_cv.R")
ls()
../
# Load features and label
library(data.table)
setwd(..)
setwd(../)
setwd("..")
ls()
setwd("../../")
ls()
feature <- read.csv("../../output/hog_feature+sift_resize.csv", header = TRUE)
feature <- fread("../../output/hog_feature+sift_resize.csv", header = TRUE)
library(data.table)
library(dplyr)
feature <- fread("../../output/hog_feature+sift_resize.csv", header = TRUE)
feature <- read.csv("../../output/hog_feature+sift.csv", header = TRUE)
setwd("~/Documents/Columbia Spring 2017/Applied Data Science/spr2017-proj3-group8/lib/Neural_Net")
feature <- read.csv("../../output/hog_feature+sift.csv", header = TRUE)
label <- fread("../../data/labels.csv")
label <- c(t(label))
hiddenLayers_newFeat <- 3
fit_train_nn <- nn_train(train = feature, y = label, hiddenLayers = hiddenLayers_newFeat)
pred_test_nn <- nn_test(fit_train_nn, feature)
sum(pred_test_nn == label)
pred_test_nn == label
fit_train_nn <- nn_train(train = feature[1:1600], y = label[1:1600], hiddenLayers = hiddenLayers_newFeat)
fit_train_nn <- nn_train(train = feature[1:1600,], y = label[1:1600], hiddenLayers = hiddenLayers_newFeat)
pred_test_nn <- nn_test(fit_train_nn, feature[1601:2000,])
pred_test_nn == label[1601:2000]
sum(pred_test_nn == label[1601:2000])
sample(feature, 1600)
qq <- nn_cv(feature, label, K=5, hiddenLayers=3)
qq
source("NN_train_test_cv.R")
